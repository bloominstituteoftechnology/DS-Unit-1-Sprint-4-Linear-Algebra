{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Eyve Geo High Dimensional Data Assignment.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eyvonne/DS-Unit-1-Sprint-4-Linear-Algebra/blob/master/module3-dimensionality-reduction/Eyve_Geo_High_Dimensional_Data_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wMWCkE1RZpM",
        "colab_type": "text"
      },
      "source": [
        "# Vertical Line Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0-g7aprRv2j",
        "colab_type": "text"
      },
      "source": [
        "## 1.1 Create two graphs, one that passes the vertical line test and one that does not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQqRvHFFqRhE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy import stats"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIJhCtF6RW_U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "verticalLine=[[2,2,2,2,2],[1,2,3,4,5]]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBsYVsxQqPZ3",
        "colab_type": "code",
        "outputId": "0b340901-3616-4111-c1a4-35afe62c0176",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "plt.plot(verticalLine[0],verticalLine[1], color='red')\n",
        "plt.plot(verticalLine[1],verticalLine[0], color='green')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f52c9f15f28>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLitpn00rBFC",
        "colab_type": "text"
      },
      "source": [
        "the red line does not pass the vertical line test, the green one does. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckeTKqMgRy7g",
        "colab_type": "text"
      },
      "source": [
        "## 1.2 Why are graphs that don't pass the vertical line test not considered \"functions?\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gtl20YeDR6x-",
        "colab_type": "text"
      },
      "source": [
        "for each input a function can have one and only one output. If a function is defined in terms of x input the y output can only be a single point on a vertical line positioned at x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g21uN62xSKSk",
        "colab_type": "text"
      },
      "source": [
        "# Functions as Relations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwkcV-EMSMNd",
        "colab_type": "text"
      },
      "source": [
        "## 2.1 Which of the following relations are functions? Why?\n",
        "\n",
        "\\begin{align}\n",
        "\\text{Relation 1: } \\{(1, 2), (3, 2), (1, 3)\\}\n",
        "\\\\\n",
        "\\text{Relation 2: } \\{(1, 3), (2, 3), (6, 7)\\}\n",
        "\\\\\n",
        "\\text{Relation 3: } \\{(9, 4), (2, 1), (9, 6)\\}\n",
        "\\\\\n",
        "\\text{Relation 4: } \\{(6, 2), (8, 3), (6, 4)\\}\n",
        "\\\\\n",
        "\\text{Relation 5: } \\{(2, 6), (2, 7), (2, 4)\\}\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxKUCVsVre_d",
        "colab_type": "text"
      },
      "source": [
        "2 is a function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0U30PrlTAAa",
        "colab_type": "text"
      },
      "source": [
        "# Functions as a mapping between dimensions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pw-OU9qmT5Ua",
        "colab_type": "text"
      },
      "source": [
        "## 3.1 for the following functions what is the dimensionality of the domain (input) and codomain (range/output)?\n",
        "\n",
        "\\begin{align}\n",
        "m(洧논_1,洧논_2,洧논_3)=(x_1+x_2, x_1+x_3, x_2+x_3)\n",
        "\\\\\n",
        "n(洧논_1,洧논_2,洧논_3,洧논_4)=(x_2^2 + x_3, x_2x_4)\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JC2xM9bPr0I0",
        "colab_type": "text"
      },
      "source": [
        "m takes in three dimensions and outputs up to three \n",
        "\n",
        "n takes in four and outputs two. Possibly three? I don't know "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4tKHjdHUevC",
        "colab_type": "text"
      },
      "source": [
        "## 3.2 Do you think it's possible to create a function that maps from a lower dimensional space to a higher dimensional space? If so, provide an example."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09BmDUgwsHcx",
        "colab_type": "text"
      },
      "source": [
        "yes- f(x)=x^2 takes in one dimension and outputs two "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nEWvwVyVWdW",
        "colab_type": "text"
      },
      "source": [
        "# Vector Transformations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1n0-6FsYVcVk",
        "colab_type": "text"
      },
      "source": [
        "## 4.1 Plug the corresponding unit vectors into each function. Use the output vectors to create a transformation matrix.\n",
        "\n",
        "\\begin{align}\n",
        "p(\\begin{bmatrix}x_1 \\\\ x_2 \\end{bmatrix}) = \\begin{bmatrix} x_1 + 3x_2 \\\\2 x_2 - x_1 \\\\  \\end{bmatrix}\n",
        "\\\\\n",
        "\\\\\n",
        "q(\\begin{bmatrix}x_1 \\\\ x_2 \\\\ x_3\\end{bmatrix}) = \\begin{bmatrix} 4x_1 + x_2 + 2x_3 \\\\2 x_2 - x_1 + 3x_3 \\\\ 5x_1 - 2x_3 + x_2  \\end{bmatrix}\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUchvRs7sqCX",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://raw.githubusercontent.com/eyvonne/csvFiles/master/Scanned%20Documents.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5HUOQIxZ2gp",
        "colab_type": "text"
      },
      "source": [
        "## 4.2 Verify that your transformation matrices are correct by choosing an input matrix and calculating the result both via the traditional functions above and also via vector-matrix multiplication."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UANR1IEaVWE",
        "colab_type": "code",
        "outputId": "2aa6f761-b390-49d1-91fe-a734ad6ec306",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "Q=np.array([[4,-1,5],[1,2,1],[2,3,2]])\n",
        "P=np.array([[1,-1],[3,2]])\n",
        "P=P.T\n",
        "Q=Q.T\n",
        "inpu=np.array([3,6,9])\n",
        "np.matmul(Q,inpu)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([36, 36, 39])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHIqgj7bxyFI",
        "colab_type": "code",
        "outputId": "15355fcf-acb1-4f30-fdf6-33c5ecadd536",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "inpu=np.array([3,6])\n",
        "np.matmul(P,inpu)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([21,  9])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEoiri3mak7j",
        "colab_type": "text"
      },
      "source": [
        "# Eigenvalues and Eigenvectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HY0R4u7anIr",
        "colab_type": "text"
      },
      "source": [
        "## 5.1 In your own words, give an explanation for the intuition behind eigenvalues and eigenvectors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PFIXuwizz3u",
        "colab_type": "text"
      },
      "source": [
        "an eigenvector is the vector around which any matrix transformation rotates around. The eigenvalue is the amount of strech applied to the eigenvector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdehMwBtatKI",
        "colab_type": "text"
      },
      "source": [
        "# The Curse of Dimensionality"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oVrJax-a3SK",
        "colab_type": "text"
      },
      "source": [
        "## 6.1 What are some of the challenges of working with high dimensional spaces?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJaxIezV0AH9",
        "colab_type": "text"
      },
      "source": [
        "human brains aren't great at imagining things in higher than 3 dimensions. \n",
        "\n",
        "the more dimensions that data has compared to its features there is a possibility of overfitting. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiBJxsZla88c",
        "colab_type": "text"
      },
      "source": [
        "## 6.2 What is the rule of thumb for how many observations you should have compared to parameters in your model?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ohR2K4i0cpo",
        "colab_type": "text"
      },
      "source": [
        "five times the number of parameters=observations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZmqdeygbHJx",
        "colab_type": "text"
      },
      "source": [
        "# Principal Component Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7iEheetpbJdN",
        "colab_type": "text"
      },
      "source": [
        "## 7.1 Load the UCI Machine Learning Repository's [Iris Dataset](https://gist.githubusercontent.com/curran/a08a1080b88344b0c8a7/raw/d546eaee765268bf2f487608c537c05e22e4b221/iris.csv) and use PCA to isolate the dataset's first and second principal components and plot them on a graph. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wy9AZVgZcHLZ",
        "colab_type": "code",
        "outputId": "bfcbe63e-5d30-46a1-9f7e-37ac64370d23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "iris=load_iris()\n",
        "irisDF=pd.DataFrame(data= np.c_[iris['data'], iris['target']],\n",
        "                     columns= iris['feature_names'] + ['target'])\n",
        "#create a second copy of the data to use sklearn on\n",
        "irisDF2=pd.DataFrame(data= np.c_[iris['data'], iris['target']],\n",
        "                     columns= iris['feature_names'] + ['target'])\n",
        "irisDF.target.value_counts()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.0    50\n",
              "1.0    50\n",
              "0.0    50\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HjRPC2C2lvL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "842ed9e4-02d1-4f07-d306-a406ff7cdb5a"
      },
      "source": [
        "#take the means of each feature\n",
        "features=iris['feature_names']\n",
        "\n",
        "X=irisDF[features].values\n",
        "means=np.mean(X.T, axis=1)\n",
        "print(means)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[5.84333333 3.05733333 3.758      1.19933333]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j08ARA3eK7Gp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "d47d82a2-ea55-4c9c-841d-489533b6b0c9"
      },
      "source": [
        "irisDF.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length (cm)</th>\n",
              "      <th>sepal width (cm)</th>\n",
              "      <th>petal length (cm)</th>\n",
              "      <th>petal width (cm)</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal length (cm)  sepal width (cm)  ...  petal width (cm)  target\n",
              "0                5.1               3.5  ...               0.2     0.0\n",
              "1                4.9               3.0  ...               0.2     0.0\n",
              "2                4.7               3.2  ...               0.2     0.0\n",
              "3                4.6               3.1  ...               0.2     0.0\n",
              "4                5.0               3.6  ...               0.2     0.0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrXLccYkKd55",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "bc8f0be2-ec02-48d6-91eb-bed6cc9443b2"
      },
      "source": [
        "np.std(irisDF)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sepal length (cm)    0.825301\n",
              "sepal width (cm)     0.434411\n",
              "petal length (cm)    1.759404\n",
              "petal width (cm)     0.759693\n",
              "target               0.816497\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSvGQlj63jG-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#center the data\n",
        "CenteredData=X-means\n",
        "#CenteredData"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vw0Uxs2L3rfI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "941cbed1-ef3f-499d-f68b-f467a2004734"
      },
      "source": [
        "#take the standard deviation of each \n",
        "std=np.std(CenteredData, axis=0)\n",
        "std"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.82530129, 0.43441097, 1.75940407, 0.75969263])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjsgBmgv4IJQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#do the standardization\n",
        "StandardizedData=CenteredData/std\n",
        "StandardizedData"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PawY8BzI4Wxb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "1b4f3db6-1993-45c5-8b51-08bf76cfa6ab"
      },
      "source": [
        "#calculate the covariance table \n",
        "cov=np.cov(StandardizedData)\n",
        "cov"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.25555467,  0.64274656,  0.93136433, ..., -0.57550534,\n",
              "        -0.15217751, -0.43781652],\n",
              "       [ 0.64274656,  0.32932363,  0.47960106, ..., -0.29454638,\n",
              "        -0.07136922, -0.21971074],\n",
              "       [ 0.93136433,  0.47960106,  0.71901892, ..., -0.4286891 ,\n",
              "        -0.05131394, -0.27998207],\n",
              "       ...,\n",
              "       [-0.57550534, -0.29454638, -0.4286891 , ...,  0.27455075,\n",
              "         0.08206143,  0.19511148],\n",
              "       [-0.15217751, -0.07136922, -0.05131394, ...,  0.08206143,\n",
              "         0.17785121,  0.14690987],\n",
              "       [-0.43781652, -0.21971074, -0.27998207, ...,  0.19511148,\n",
              "         0.14690987,  0.2246618 ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RY-kn76d4rhw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get the eigenvalues and vectors of the cov matrix\n",
        "values, vectors=np.linalg.eig(cov)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-Xt_pZg5Nr4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "projected=vectors.dot(CenteredData)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Dz31CG56CoA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "scaler=StandardScaler()\n",
        "Z=scaler.fit_transform(irisDF2[features])\n",
        "#z is the standardized data\n",
        "\n",
        "pca=PCA(4)\n",
        "pca.fit(Z)\n",
        "\n",
        "b=pca.transform(Z)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edPY9Z70CxCE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "outputId": "38de6add-d89f-4d54-bee5-5ec498c78875"
      },
      "source": [
        "projected[-10:]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 9.34246202e-01+0.31942888j, -1.29207612e-01+0.09622556j,\n",
              "         1.76968429e+00+0.4884561j ,  7.65384597e-01+0.36340779j],\n",
              "       [ 8.23253798e-01-0.36365971j, -1.06843660e-01-0.45914911j,\n",
              "         1.33546503e+00-0.44041406j,  6.85618450e-01-0.16385519j],\n",
              "       [-6.05253806e-01+0.14906725j, -5.45030139e-02+0.04375685j,\n",
              "        -4.64568550e-01+0.12311127j, -1.92794693e-01+0.12964826j],\n",
              "       [-1.09103986e-01+0.45325805j,  3.63747166e-01+0.31030404j,\n",
              "        -8.02711287e-01+0.34853444j, -1.72931990e-01+0.16637031j],\n",
              "       [ 4.91651647e-01+0.20818294j,  9.62478385e-02+0.09115791j,\n",
              "         1.39733523e+00+0.12659608j,  6.48115999e-01-0.14364319j],\n",
              "       [ 1.27758077e+00+0.02498324j,  3.04067890e-03-0.23210482j,\n",
              "         2.61772813e+00+0.11095369j,  9.90216924e-01-0.12853809j],\n",
              "       [-8.38408320e-01-0.31683154j,  2.63158481e-01-0.04194284j,\n",
              "        -1.68578538e+00-0.42559364j, -8.57912879e-01-0.1974511j ],\n",
              "       [-7.42678655e-01-0.42898982j, -3.98028690e-02-0.1080912j ,\n",
              "        -1.62067079e+00-0.58911241j, -5.01063626e-01+0.00326397j],\n",
              "       [ 9.82546052e-01+0.26764631j, -2.53985144e-01+0.16007177j,\n",
              "         2.06950485e+00+0.21486407j,  8.81445306e-01+0.24495826j],\n",
              "       [-1.83742072e-01+0.12293715j, -2.10549403e-03-0.00532286j,\n",
              "        -1.99906262e-02+0.08547475j,  2.98851585e-01+0.23175927j]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbFWV0oW_LQt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "39c1c018-c91d-4035-e711-a848a6b1faaf"
      },
      "source": [
        "b[0:10]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-2.26470281,  0.4800266 , -0.12770602, -0.0241682 ],\n",
              "       [-2.08096115, -0.67413356, -0.23460885, -0.10300677],\n",
              "       [-2.36422905, -0.34190802,  0.04420148, -0.02837705],\n",
              "       [-2.29938422, -0.59739451,  0.09129011,  0.06595556],\n",
              "       [-2.38984217,  0.64683538,  0.0157382 ,  0.03592281],\n",
              "       [-2.07563095,  1.48917752,  0.02696829, -0.00660818],\n",
              "       [-2.44402884,  0.0476442 ,  0.3354704 ,  0.03677556],\n",
              "       [-2.23284716,  0.22314807, -0.0886955 ,  0.0246121 ],\n",
              "       [-2.33464048, -1.11532768,  0.14507686,  0.02685922],\n",
              "       [-2.18432817, -0.46901356, -0.25376557,  0.03989929]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7TMVXFcD5Pe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8fe629fa-a13f-4186-ffb3-ba5bab866ebd"
      },
      "source": [
        "StandardizedData==Z"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False,  True],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False,  True],\n",
              "       [False, False, False,  True],\n",
              "       [False, False, False,  True],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False,  True],\n",
              "       [False, False, False,  True],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False,  True],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False,  True],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False,  True],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False,  True],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False,  True],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False,  True],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False,  True],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False,  True],\n",
              "       [False, False, False,  True],\n",
              "       [False, False, False,  True],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False,  True],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False,  True],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False,  True],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False,  True],\n",
              "       [False, False, False,  True],\n",
              "       [False, False, False,  True],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False,  True],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False,  True],\n",
              "       [False, False, False,  True],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False,  True],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False,  True],\n",
              "       [False, False, False,  True],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False,  True],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False,  True],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False,  True],\n",
              "       [False, False, False,  True],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False,  True],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False,  True],\n",
              "       [False, False, False, False],\n",
              "       [False, False, False, False]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQx7UvsucIrL",
        "colab_type": "text"
      },
      "source": [
        "# Stretch Goal\n",
        "\n",
        "## 1) Do NOT work on the stretch goal until you feel like you have a firm grasp of eigenvectors, eigenvalues, and PCA. Prioritize self-study over the stretch goal if you are not comfortable with those topics yet.\n",
        "\n",
        "## 2) Explore further the intuition behind eigenvalues and eigenvectors by creating your very own eigenfaces:\n",
        "\n",
        "<center>![Eigenfaces](https://i.pinimg.com/236x/1c/f1/01/1cf101a9859437a5d096a04b05be06b4--faces-tattoo.jpg)</center>\n",
        "\n",
        "You don't necessarily have to use this resource, but this will get you started: \n",
        "[Eigenface Tutorial](https://sandipanweb.wordpress.com/2018/01/06/eigenfaces-and-a-simple-face-detector-with-pca-svd-in-python/)"
      ]
    }
  ]
}