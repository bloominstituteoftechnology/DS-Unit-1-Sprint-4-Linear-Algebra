{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Clustering Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tclack88/DS-Unit-1-Sprint-4-Linear-Algebra/blob/master/module4-clustering/Cell_Clustering_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-3rVFtGLMJM",
        "colab_type": "text"
      },
      "source": [
        "# K-Means Clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VS3FFSFLR3a",
        "colab_type": "text"
      },
      "source": [
        "# 1) Use the \"Breast Cancer Wisconsin (Diagnostic) Data Set\" from Kaggle to try and cluster types of cancer cells. \n",
        "\n",
        "Here's the original dataset for your reference:\n",
        "\n",
        "<https://www.kaggle.com/uciml/breast-cancer-wisconsin-data>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "899RK3bBn4OE",
        "colab_type": "text"
      },
      "source": [
        "## This is a supervised learning dataset\n",
        "\n",
        "(Because it has **labels** - The \"diagnosis\" column.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ws5R9X6hLJQ2",
        "colab_type": "code",
        "outputId": "b1ab2da3-036c-4978-9fff-26c847e704ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA # You don't necessarily have to use this\n",
        "from sklearn.cluster import KMeans # You don't necessarily have to use this\n",
        "from sklearn.preprocessing import StandardScaler # You don't necessarily have to use this\n",
        "\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/ryanleeallred/datasets/master/Cancer_Cells.csv\")\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(569, 33)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id diagnosis  ...  fractal_dimension_worst  Unnamed: 32\n",
              "0    842302         M  ...                  0.11890          NaN\n",
              "1    842517         M  ...                  0.08902          NaN\n",
              "2  84300903         M  ...                  0.08758          NaN\n",
              "3  84348301         M  ...                  0.17300          NaN\n",
              "4  84358402         M  ...                  0.07678          NaN\n",
              "\n",
              "[5 rows x 33 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHDDqaU-ove4",
        "colab_type": "text"
      },
      "source": [
        "## Now it's an unsupervised learning dataset\n",
        "\n",
        "(Because we've removed the diagnosis label) - Use this version."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86MHoPJon_aC",
        "colab_type": "code",
        "outputId": "afc40cf8-4ab4-4db5-90cb-deefb5ef702e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "df_original = df.copy()\n",
        "df = df.drop('diagnosis', axis=1)\n",
        "df.head()"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  radius_mean  ...  fractal_dimension_worst  Unnamed: 32\n",
              "0    842302        17.99  ...                  0.11890          NaN\n",
              "1    842517        20.57  ...                  0.08902          NaN\n",
              "2  84300903        19.69  ...                  0.08758          NaN\n",
              "3  84348301        11.42  ...                  0.17300          NaN\n",
              "4  84358402        20.29  ...                  0.07678          NaN\n",
              "\n",
              "[5 rows x 32 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rskC80k3OKMA",
        "colab_type": "text"
      },
      "source": [
        "## Let's do it!\n",
        "\n",
        "- You might want to do some data exploration to see if you can find specific columns that will help you find distinct clusters of cells\n",
        "- You might want to use the elbow method to decide on the number of clusters to use.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8xzhtHupvb9",
        "colab_type": "text"
      },
      "source": [
        "### By hand - 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMGasNF9rXaJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.drop(columns=['id','Unnamed: 32']) # 'Unnamed:32' appears to be a useless array of nans\n",
        "                                           # 'id' is not necessary. (shoutout to David Nagy for catching this)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyTNeK3JyFCi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "048c0932-d950-473a-c80a-f032f007075d"
      },
      "source": [
        "# Using a k-means library first to choose the best number of clusters\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn import metrics\n",
        "from scipy.spatial.distance import cdist\n",
        "\n",
        "distortions = []\n",
        "K = range(1,10)\n",
        "for k in K:\n",
        "  kmean_model = KMeans(n_clusters=k).fit(df)\n",
        "  kmean_model.fit(df)\n",
        "  distortions.append(sum(np.min(cdist(df,kmean_model.cluster_centers_,'euclidean'),axis=1))/df.shape[0])\n",
        "  \n",
        "plt.plot(K,distortions)\n",
        "plt.xlabel('choice of k')\n",
        "plt.ylabel('Distance from cluster centers');"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUoYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nO_Tn_lKIcs4",
        "colab_type": "text"
      },
      "source": [
        "From the above elbow plot, 2 clusters centers is ideal, but then later I looked at the dataset and realized there's only two things being predicted inthe diagnosis, M, and B (malignant and benign) so we only need two clusters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUqMqCHRgj0D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "outputId": "4b94f8ad-4838-4bac-946e-c2eb06202f79"
      },
      "source": [
        "n_clusters = 2\n",
        "centroids = df.sample(n_clusters)\n",
        "\n",
        "\n",
        "\n",
        "def get_centroids(df, column_header):\n",
        "  headers = []\n",
        "  values = []\n",
        "  for col in list(df.columns):\n",
        "    header = col\n",
        "    headers.append(header)\n",
        "    value = [df[col][df[column_header] == i].mean() for i in range(n_clusters)]\n",
        "    values.append(value)\n",
        "    data = dict(zip(headers,values))\n",
        "  return pd.DataFrame(data)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def find_nearest_centroid(df, centroids):\n",
        "  last_centroids = [np.random.choice(list(range(n_clusters)))] * df.shape[0]\n",
        "  df_temp = df.copy()\n",
        "  i = 0\n",
        "  \n",
        "  while True:\n",
        "    if i > 0:\n",
        "      centroids = get_centroids(df_temp, 'cluster' + str(i-1))\n",
        "    \n",
        "    col_names = list(df.columns)\n",
        "    distances = cdist(df_temp[col_names], centroids[col_names])\n",
        "    nearest_centroids = np.argmin(distances, axis=1)\n",
        "    \n",
        "    df_temp['cluster' + str(i)] = nearest_centroids\n",
        "    \n",
        "    if (list(nearest_centroids) == list(last_centroids)):\n",
        "      return df_temp\n",
        "    else:\n",
        "      i +=1\n",
        "      last_centroids = nearest_centroids\n",
        "      \n",
        "      \n",
        "      \n",
        "  \n",
        "  \n",
        "hand_kmeans = find_nearest_centroid(df, centroids)\n",
        "hand_kmeans.head(10)"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>cluster0</th>\n",
              "      <th>cluster1</th>\n",
              "      <th>cluster2</th>\n",
              "      <th>cluster3</th>\n",
              "      <th>cluster4</th>\n",
              "      <th>cluster5</th>\n",
              "      <th>cluster6</th>\n",
              "      <th>cluster7</th>\n",
              "      <th>cluster8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>12.45</td>\n",
              "      <td>15.70</td>\n",
              "      <td>82.57</td>\n",
              "      <td>477.1</td>\n",
              "      <td>0.12780</td>\n",
              "      <td>0.17000</td>\n",
              "      <td>0.15780</td>\n",
              "      <td>0.08089</td>\n",
              "      <td>0.2087</td>\n",
              "      <td>0.07613</td>\n",
              "      <td>0.3345</td>\n",
              "      <td>0.8902</td>\n",
              "      <td>2.217</td>\n",
              "      <td>27.19</td>\n",
              "      <td>0.007510</td>\n",
              "      <td>0.03345</td>\n",
              "      <td>0.03672</td>\n",
              "      <td>0.01137</td>\n",
              "      <td>0.02165</td>\n",
              "      <td>0.005082</td>\n",
              "      <td>15.47</td>\n",
              "      <td>23.75</td>\n",
              "      <td>103.40</td>\n",
              "      <td>741.6</td>\n",
              "      <td>0.1791</td>\n",
              "      <td>0.5249</td>\n",
              "      <td>0.5355</td>\n",
              "      <td>0.1741</td>\n",
              "      <td>0.3985</td>\n",
              "      <td>0.12440</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>18.25</td>\n",
              "      <td>19.98</td>\n",
              "      <td>119.60</td>\n",
              "      <td>1040.0</td>\n",
              "      <td>0.09463</td>\n",
              "      <td>0.10900</td>\n",
              "      <td>0.11270</td>\n",
              "      <td>0.07400</td>\n",
              "      <td>0.1794</td>\n",
              "      <td>0.05742</td>\n",
              "      <td>0.4467</td>\n",
              "      <td>0.7732</td>\n",
              "      <td>3.180</td>\n",
              "      <td>53.91</td>\n",
              "      <td>0.004314</td>\n",
              "      <td>0.01382</td>\n",
              "      <td>0.02254</td>\n",
              "      <td>0.01039</td>\n",
              "      <td>0.01369</td>\n",
              "      <td>0.002179</td>\n",
              "      <td>22.88</td>\n",
              "      <td>27.66</td>\n",
              "      <td>153.20</td>\n",
              "      <td>1606.0</td>\n",
              "      <td>0.1442</td>\n",
              "      <td>0.2576</td>\n",
              "      <td>0.3784</td>\n",
              "      <td>0.1932</td>\n",
              "      <td>0.3063</td>\n",
              "      <td>0.08368</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>13.71</td>\n",
              "      <td>20.83</td>\n",
              "      <td>90.20</td>\n",
              "      <td>577.9</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>0.16450</td>\n",
              "      <td>0.09366</td>\n",
              "      <td>0.05985</td>\n",
              "      <td>0.2196</td>\n",
              "      <td>0.07451</td>\n",
              "      <td>0.5835</td>\n",
              "      <td>1.3770</td>\n",
              "      <td>3.856</td>\n",
              "      <td>50.96</td>\n",
              "      <td>0.008805</td>\n",
              "      <td>0.03029</td>\n",
              "      <td>0.02488</td>\n",
              "      <td>0.01448</td>\n",
              "      <td>0.01486</td>\n",
              "      <td>0.005412</td>\n",
              "      <td>17.06</td>\n",
              "      <td>28.14</td>\n",
              "      <td>110.60</td>\n",
              "      <td>897.0</td>\n",
              "      <td>0.1654</td>\n",
              "      <td>0.3682</td>\n",
              "      <td>0.2678</td>\n",
              "      <td>0.1556</td>\n",
              "      <td>0.3196</td>\n",
              "      <td>0.11510</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>13.00</td>\n",
              "      <td>21.82</td>\n",
              "      <td>87.50</td>\n",
              "      <td>519.8</td>\n",
              "      <td>0.12730</td>\n",
              "      <td>0.19320</td>\n",
              "      <td>0.18590</td>\n",
              "      <td>0.09353</td>\n",
              "      <td>0.2350</td>\n",
              "      <td>0.07389</td>\n",
              "      <td>0.3063</td>\n",
              "      <td>1.0020</td>\n",
              "      <td>2.406</td>\n",
              "      <td>24.32</td>\n",
              "      <td>0.005731</td>\n",
              "      <td>0.03502</td>\n",
              "      <td>0.03553</td>\n",
              "      <td>0.01226</td>\n",
              "      <td>0.02143</td>\n",
              "      <td>0.003749</td>\n",
              "      <td>15.49</td>\n",
              "      <td>30.73</td>\n",
              "      <td>106.20</td>\n",
              "      <td>739.3</td>\n",
              "      <td>0.1703</td>\n",
              "      <td>0.5401</td>\n",
              "      <td>0.5390</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.4378</td>\n",
              "      <td>0.10720</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>12.46</td>\n",
              "      <td>24.04</td>\n",
              "      <td>83.97</td>\n",
              "      <td>475.9</td>\n",
              "      <td>0.11860</td>\n",
              "      <td>0.23960</td>\n",
              "      <td>0.22730</td>\n",
              "      <td>0.08543</td>\n",
              "      <td>0.2030</td>\n",
              "      <td>0.08243</td>\n",
              "      <td>0.2976</td>\n",
              "      <td>1.5990</td>\n",
              "      <td>2.039</td>\n",
              "      <td>23.94</td>\n",
              "      <td>0.007149</td>\n",
              "      <td>0.07217</td>\n",
              "      <td>0.07743</td>\n",
              "      <td>0.01432</td>\n",
              "      <td>0.01789</td>\n",
              "      <td>0.010080</td>\n",
              "      <td>15.09</td>\n",
              "      <td>40.68</td>\n",
              "      <td>97.65</td>\n",
              "      <td>711.4</td>\n",
              "      <td>0.1853</td>\n",
              "      <td>1.0580</td>\n",
              "      <td>1.1050</td>\n",
              "      <td>0.2210</td>\n",
              "      <td>0.4366</td>\n",
              "      <td>0.20750</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   radius_mean  texture_mean  perimeter_mean  ...  cluster6  cluster7  cluster8\n",
              "0        17.99         10.38          122.80  ...         1         1         1\n",
              "1        20.57         17.77          132.90  ...         1         1         1\n",
              "2        19.69         21.25          130.00  ...         1         1         1\n",
              "3        11.42         20.38           77.58  ...         0         0         0\n",
              "4        20.29         14.34          135.10  ...         1         1         1\n",
              "5        12.45         15.70           82.57  ...         0         0         0\n",
              "6        18.25         19.98          119.60  ...         1         1         1\n",
              "7        13.71         20.83           90.20  ...         0         0         0\n",
              "8        13.00         21.82           87.50  ...         0         0         0\n",
              "9        12.46         24.04           83.97  ...         0         0         0\n",
              "\n",
              "[10 rows x 39 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6S-mkPgsplHg",
        "colab_type": "text"
      },
      "source": [
        "### By hand - 2\n",
        "Ignore for now"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iDdibIGKmYs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### IGNORE THIS - SIDE WORK ########\n",
        "\n",
        "# df_sample = df.iloc[:,1:3]\n",
        "# df_sample.plot.scatter('radius_mean','texture_mean')\n",
        "# centroids= df_sample.sample(2)\n",
        "\n",
        "# print(centroids)\n",
        "# print(df_sample.head())\n",
        "\n",
        "# def find_centroids(df, new_groups):\n",
        "#   centroids = []\n",
        "#  # for col in df:\n",
        "\n",
        "    \n",
        "# def check_for_convergence(df):\n",
        "#    if (df.iloc[:,-1].equals(df.iloc[:,-2])) or (df.iloc[:,-1].equals(df.iloc[:,-3])):\n",
        "#       return True\n",
        "#    else:\n",
        "#     return False\n",
        "    \n",
        "    \n",
        "# def add_cluster_iteration(df_sample,i):\n",
        "#   global centroids\n",
        "#   distances = cdist(df_sample,centroids,'euclidean')\n",
        "#   new_groups = pd.Series(np.argmin(distances,axis=1))\n",
        "#   df_sample['cluster_'+str(i)] = new_groups\n",
        "#   centroids = find_centroids(df_sample,new_groups)\n",
        "#   return df_sample\n",
        "\n",
        "  \n",
        "# # new_df_sample = add_cluster_iteration(df_sample,1)\n",
        "# # new_df_sample\n",
        "\n",
        "# def run_kmeans(df):\n",
        "#   converged = check_for_convergence(df)\n",
        "#   i = 1\n",
        "#   while not converged:\n",
        "#     df = add_cluster_iteration(df,i)\n",
        "#     i += 1\n",
        "#     converged = check_for_convergence(df)\n",
        "#   return df\n",
        "\n",
        "# run_kmeans(df_sample)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3b6RXZF_pzEt",
        "colab_type": "text"
      },
      "source": [
        "### With libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLMcbKjsp1sA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "kmeans = KMeans(n_clusters = 2)\n",
        "kmeans.fit(df)\n",
        "\n",
        "library_labels = kmeans.labels_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTWyrFiNpMOn",
        "colab_type": "text"
      },
      "source": [
        "## Check you work: \n",
        "\n",
        "This is something that in a truly unsupervised learning situation **WOULD NOT BE POSSIBLE**. But for educational purposes go back and grab the true dianosis column (label) from the original dataset. Take your cluster labels and compare them to the original diagnosis column. You can make scatterplots for each to see how they compare or you can calculate a percent accuracy score like: \n",
        "\\begin{align}\n",
        "\\frac{\\text{Num Correct Labels}}{\\text{Num Total Observations}}\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDfMEnK1pPCU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_labels(letter):\n",
        "  if letter == 'M':\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "actual_labels = df_original.diagnosis.apply(convert_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLUr4IxFs82F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hand_labels = hand_kmeans.iloc[:,-1]\n",
        "\n",
        "hand_labels = np.array(hand_labels)\n",
        "actual_labels = np.array(actual_labels)  #convert pd series to nparray\n",
        "\n",
        "#library_labels = (library_labels + 1) % 1   # A means to reverse labels \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQjQxW19spyy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "1763ce91-8a1c-4300-f671-41d9bc77a1aa"
      },
      "source": [
        "print('actual labels :',actual_labels[0:25])\n",
        "print('hand labels:   ',hand_labels[0:25])\n",
        "print('library labels:',library_labels[0:25])"
      ],
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "actual labels : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1]\n",
            "hand labels:    [1 1 1 0 1 0 1 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 1 1]\n",
            "library labels: [1 1 1 0 1 0 1 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ee8fYfMft-OS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "908e76bc-5404-4d88-bbe7-f105e07b28c6"
      },
      "source": [
        "compare = pd.DataFrame({'actual':actual_labels,'hand':hand_labels,'library':library_labels})\n",
        "print('Actual vs hand:\\n',compare.actual.eq(compare.hand).sum()/compare.shape[0])\n",
        "print('\\nlibrary vs hand:\\n',compare.actual.eq(compare.library).sum()/compare.shape[0])"
      ],
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Actual vs hand:\n",
            " 0.8541300527240774\n",
            "\n",
            "library vs hand:\n",
            " 0.8541300527240774\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BedOTS0eJ9_K",
        "colab_type": "text"
      },
      "source": [
        "# 2) Perform PCA on your dataset first and *then* use k-means clustering. \n",
        "\n",
        "- You need to standardize your data before PCA.\n",
        "- First try clustering just on PC1 and PC2 so that you can make a scatterplot of your clustering.\n",
        "- Then use use a scree plot to decide how many principal components to include in your clustering, and use however many principal components you need in order to retain 90% of the variation of the original dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYmlUxjjDKtX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "processed_df = (df - df.mean())/df.std()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dW1AeAK8PNah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(6)\n",
        "pca.fit(processed_df)\n",
        "\n",
        "data = pca.fit_transform(processed_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQMsbD7AyiOd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kmeans = KMeans(n_clusters = 2)\n",
        "kmeans.fit(data)\n",
        "\n",
        "pca_lib_labels = kmeans.labels_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkrfbzfBROpP",
        "colab_type": "text"
      },
      "source": [
        "## Check your work: \n",
        "\n",
        "- Compare your PC1, PC2 clustering scatterplot to the clustering scatterplots you made on the raw data\n",
        "- Calculate accuracy scores for both the PC1,PC2 Principal component clustering and the 90% of explained variance clustering.\n",
        "\n",
        "How do your accuracy scores when preprocessing the data with PCA compare to the accuracy when clustering on the raw data?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6ZNhJ5OI1L9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3adfe560-47a8-4b0e-db1b-cb85ff31370f"
      },
      "source": [
        "pca.explained_variance_ratio_"
      ],
      "execution_count": 263,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.44272026, 0.18971182, 0.09393163, 0.06602135, 0.05495768,\n",
              "       0.04024522])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 263
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSdTTLNiz3vr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0177ba11-f71a-4ae4-e656-734b9083a5a9"
      },
      "source": [
        "print(\"Accuracy after applying pca to data:\")\n",
        "\n",
        "actual_pca_compare = pd.DataFrame({'actual':actual_labels,'pca':pca_lib_labels})\n",
        "actual_pca_compare.actual.eq(actual_pca_compare.pca).sum()/actual_pca_compare.shape[0]"
      ],
      "execution_count": 259,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy after applying pca to data:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9103690685413005"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 259
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKBwVaGOOYsq",
        "colab_type": "text"
      },
      "source": [
        "# Stretch Goals:\n",
        "\n",
        "- Study for the Sprint Challenge\n",
        "- Work on your Data Storytelling Project\n",
        "- Practice your two-minute presentation for your Data Storytelling Project"
      ]
    }
  ]
}